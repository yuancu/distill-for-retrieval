{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Model Distillation Driver\n",
    "\n",
    "## Plan Overview\n",
    "\n",
    "**Teacher**: infly/inf-retriever-v1-pro (3584d)\n",
    "\n",
    "**Student**: sentence-transformers/all-mpnet-base-v2 (768d) + Projection (768→1536→3584)\n",
    "\n",
    "**Phase 1**: General Distillation\n",
    "- Loss: MSE (0.4) + Cosine (0.6)\n",
    "- Data: MS MARCO + NQ + HotpotQA\n",
    "\n",
    "**Phase 2**: Task-Specific\n",
    "- Loss: InfoNCE (0.8) + MSE (0.2)\n",
    "- Data: MS MARCO with hard negatives\n",
    "- Temperature: 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import logging\n",
    "\n",
    "# Import from distill module\n",
    "from distill import (\n",
    "    ProjectionLayer,\n",
    "    StudentModelWithProjection,\n",
    "    train_phase1,\n",
    "    train_phase2,\n",
    "    evaluate_retrieval\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Available GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "TEACHER_MODEL = \"infly/inf-retriever-v1-pro\"\n",
    "STUDENT_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "TEACHER_DIM = 3584\n",
    "STUDENT_DIM = 768\n",
    "PROJECTION_HIDDEN_DIM = 1536\n",
    "\n",
    "# Phase 1 configuration\n",
    "PHASE1_CONFIG = {\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 2e-5,\n",
    "    'warmup_steps': 1000,\n",
    "    'num_epochs': 1,\n",
    "    'mse_weight': 0.4,\n",
    "    'cosine_weight': 0.6,\n",
    "    'max_length': 512,\n",
    "    'gradient_accumulation_steps': 4,\n",
    "    'max_samples_per_dataset': 100000\n",
    "}\n",
    "\n",
    "# Phase 2 configuration\n",
    "PHASE2_CONFIG = {\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 5e-6,\n",
    "    'warmup_steps': 500,\n",
    "    'num_epochs': 3,\n",
    "    'infonce_weight': 0.8,\n",
    "    'mse_weight': 0.2,\n",
    "    'temperature': 0.02,\n",
    "    'max_length': 512,\n",
    "    'num_negatives': 7,\n",
    "    'gradient_accumulation_steps': 8,\n",
    "    'max_samples': 500000\n",
    "}\n",
    "\n",
    "# Paths\n",
    "OUTPUT_DIR = \"./checkpoints\"\n",
    "PHASE1_CHECKPOINT = os.path.join(OUTPUT_DIR, \"phase1_best\")\n",
    "PHASE2_CHECKPOINT = os.path.join(OUTPUT_DIR, \"phase2_best\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load teacher model (frozen)\n",
    "logger.info(f\"Loading teacher model: {TEACHER_MODEL}\")\n",
    "teacher_model = SentenceTransformer(TEACHER_MODEL)\n",
    "teacher_model.eval()\n",
    "for param in teacher_model.parameters():\n",
    "    param.requires_grad = False\n",
    "teacher_model = teacher_model.to(device)\n",
    "\n",
    "# Create student model with projection\n",
    "logger.info(f\"Loading student model: {STUDENT_MODEL}\")\n",
    "projection_layer = ProjectionLayer(STUDENT_DIM, PROJECTION_HIDDEN_DIM, TEACHER_DIM)\n",
    "student_model = StudentModelWithProjection(STUDENT_MODEL, projection_layer)\n",
    "student_model = student_model.to(device)\n",
    "\n",
    "# Test models\n",
    "test_text = [\"This is a test sentence.\"]\n",
    "with torch.no_grad():\n",
    "    teacher_emb = teacher_model.encode(test_text, convert_to_tensor=True)\n",
    "    student_emb_768 = student_model.encode(test_text, return_projected=False)\n",
    "    student_emb_3584 = student_model.encode(test_text, return_projected=True)\n",
    "    \n",
    "print(f\"\\nModel test successful:\")\n",
    "print(f\"  Teacher: {teacher_emb.shape}\")\n",
    "print(f\"  Student (768d): {student_emb_768.shape}\")\n",
    "print(f\"  Student (3584d): {student_emb_3584.shape}\")\n",
    "\n",
    "# Count parameters\n",
    "student_params = sum(p.numel() for p in student_model.student.parameters())\n",
    "projection_params = sum(p.numel() for p in student_model.projection.parameters())\n",
    "print(f\"\\nParameter counts:\")\n",
    "print(f\"  Student base: {student_params:,}\")\n",
    "print(f\"  Projection: {projection_params:,}\")\n",
    "print(f\"  Total: {student_params + projection_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phase 1: General Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Phase 1 training\n",
    "logger.info(\"Starting Phase 1: General Distillation\")\n",
    "logger.info(f\"Config: {PHASE1_CONFIG}\")\n",
    "\n",
    "student_model = train_phase1(\n",
    "    student_model, \n",
    "    teacher_model, \n",
    "    PHASE1_CONFIG, \n",
    "    device, \n",
    "    PHASE1_CHECKPOINT\n",
    ")\n",
    "\n",
    "logger.info(f\"Phase 1 complete. Best model saved to: {PHASE1_CHECKPOINT}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Phase 1 Checkpoint and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Phase 1 checkpoint (if resuming or skipping Phase 1)\n",
    "# Uncomment if you want to load a saved Phase 1 model\n",
    "# checkpoint = torch.load(f\"{PHASE1_CHECKPOINT}.pt\")\n",
    "# student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# logger.info(f\"Loaded Phase 1 checkpoint from: {PHASE1_CHECKPOINT}.pt\")\n",
    "\n",
    "# Quick evaluation after Phase 1\n",
    "logger.info(\"\\nEvaluating Phase 1 model...\")\n",
    "test_queries = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"How does photosynthesis work?\",\n",
    "    \"Explain quantum mechanics\"\n",
    "]\n",
    "\n",
    "with torch.no_grad():\n",
    "    teacher_embs = teacher_model.encode(test_queries, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    student_embs = student_model.encode(test_queries, normalize=True, return_projected=True)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = torch.nn.functional.cosine_similarity(teacher_embs, student_embs, dim=1)\n",
    "    print(f\"Average cosine similarity with teacher: {cosine_sim.mean().item():.4f}\")\n",
    "    print(f\"Per-query similarities: {cosine_sim.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Phase 2: Task-Specific Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Phase 2 training\n",
    "student_model = train_phase2(\n",
    "    student_model, \n",
    "    teacher_model, \n",
    "    PHASE2_CONFIG, \n",
    "    device, \n",
    "    PHASE2_CHECKPOINT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Model to Artifacts with Proper SentenceTransformer Format\n",
    "\n",
    "from distill.save_model import save_distilled_model_to_artifacts\n",
    "\n",
    "# Save the model with projection to artifacts/\n",
    "output_path = save_distilled_model_to_artifacts(\n",
    "    student_model=student_model,\n",
    "    checkpoint_path=f\"{PHASE1_CHECKPOINT}.pt\",\n",
    "    artifacts_dir=\"./artifacts\",\n",
    "    model_name=\"distilled-mpnet-3584d\"\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"Model saved and ready to use!\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nLoad it in any script with:\")\n",
    "print(f\">>> from sentence_transformers import SentenceTransformer\")\n",
    "print(f\">>> model = SentenceTransformer('{output_path}')\")\n",
    "print(f\">>> embeddings = model.encode(['your texts here'])  # Shape: (N, 3584)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('./artifacts/distilled-mpnet-3584d')\n",
    "embeddings = model.encode(['your texts here'])  # Shape: (N, 3584)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best Phase 2 checkpoint\n",
    "checkpoint = torch.load(f\"{PHASE2_CHECKPOINT}.pt\")\n",
    "student_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Save the complete model\n",
    "final_model_path = os.path.join(OUTPUT_DIR, \"distilled_mpnet_final\")\n",
    "os.makedirs(final_model_path, exist_ok=True)\n",
    "\n",
    "# Save student base model\n",
    "student_model.student.save(os.path.join(final_model_path, \"student_base\"))\n",
    "\n",
    "# Save projection layer\n",
    "torch.save(\n",
    "    student_model.projection.state_dict(),\n",
    "    os.path.join(final_model_path, \"projection_layer.pt\")\n",
    ")\n",
    "\n",
    "logger.info(f\"\\nFinal model saved to: {final_model_path}\")\n",
    "logger.info(\"  - student_base/: Base sentence-transformer model (768d)\")\n",
    "logger.info(\"  - projection_layer.pt: Projection weights (768→3584)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Distillation Complete!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nYou can now use the model for inference:\")\n",
    "print(f\"  - For fast retrieval: Use 768d embeddings (student only)\")\n",
    "print(f\"  - For hybrid system: Use 3584d embeddings (student + projection)\")\n",
    "print(f\"  - Switch to teacher (3584d native) for hard cases\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Encode queries and documents\n",
    "example_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How does neural network work?\"\n",
    "]\n",
    "\n",
    "example_docs = [\n",
    "    \"Machine learning is a subset of artificial intelligence.\",\n",
    "    \"Neural networks are computing systems inspired by biological neural networks.\"\n",
    "]\n",
    "\n",
    "# Encode with student (3584d for hybrid system)\n",
    "with torch.no_grad():\n",
    "    query_emb = student_model.encode(example_queries, normalize=True, return_projected=True)\n",
    "    doc_emb = student_model.encode(example_docs, normalize=True, return_projected=True)\n",
    "    \n",
    "    similarities = torch.matmul(query_emb, doc_emb.T)\n",
    "    print(\"\\nSimilarity scores (student model, 3584d):\")\n",
    "    print(similarities)\n",
    "\n",
    "# Compare with teacher\n",
    "with torch.no_grad():\n",
    "    teacher_query_emb = teacher_model.encode(example_queries, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    teacher_doc_emb = teacher_model.encode(example_docs, convert_to_tensor=True, normalize_embeddings=True)\n",
    "    \n",
    "    teacher_similarities = torch.matmul(teacher_query_emb, teacher_doc_emb.T)\n",
    "    print(\"\\nSimilarity scores (teacher model, 3584d):\")\n",
    "    print(teacher_similarities)\n",
    "    \n",
    "    print(f\"\\nAverage difference: {torch.abs(similarities - teacher_similarities).mean().item():.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
